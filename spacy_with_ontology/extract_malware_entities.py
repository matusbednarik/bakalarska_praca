import pandas as pd
import spacy
import os
from owlready2 import get_ontology
from spacy.pipeline import EntityRuler

def load_spacy_model(ontology_terms):
    """Load the English language model and add EntityRuler for ontology terms.

    Args:
        ontology_terms (dict): Dictionary of ontology terms with their categories.

    Returns:
        spacy.lang: A spaCy language model with enhanced NER capabilities.
    """
    nlp = spacy.load("en_core_web_trf")

    # Print NER labels to verify
    print("NER labels:", nlp.get_pipe("ner").labels)

    # Add the EntityRuler to the pipeline using its string name
    ruler = nlp.add_pipe("entity_ruler", after="ner", config={"overwrite_ents": True})

    # Load patterns from ontology terms
    patterns = load_ontology_patterns(ontology_terms)
    ruler.add_patterns(patterns)

    return nlp

def extract_meaningful_relationships(ent, sent):
    """Extract relationships for a given entity in a sentence"""
    relationships = []
    excluded_deps = {'punct', 'case', 'space', 'det'}
    # Related phrase is actually a subtree for that token
    for token in sent:
        if token.head == ent.root or ent.root.head == token:
            if token.dep_ not in excluded_deps and token.pos_ not in ('PUNCT', 'SPACE'):
                related_phrase = " ".join([child.text for child in token.subtree])
                relationships.append({
                    'related_phrase': related_phrase,
                    'relation_type': token.dep_,
                    'related_to': token.head.text if token.head != ent.root else ent.root.text
                })
    return relationships

def load_ontology_terms(ontology_path):
    """Load ontology terms with their basic categories only"""
    ontology = get_ontology(ontology_path).load()
    terms = {}
    
    # Add classes
    for cls in ontology.classes():
        terms[cls.name.lower()] = {'type': 'class'}
    
    # Add object properties  
    for prop in ontology.object_properties():
        terms[prop.name.lower()] = {'type': 'relation'}
        
    # Add data properties
    for prop in ontology.data_properties():
        terms[prop.name.lower()] = {'type': 'relation'}
    
    # Add individuals
    for ind in ontology.individuals():
        terms[ind.name.lower()] = {'type': 'instance'}

    return terms

def load_ontology_patterns(ontology_terms):
    """Create EntityRuler patterns from ontology terms with case-insensitive matching."""
    patterns = []
    for term, info in ontology_terms.items():
        if info['type'] == 'class':
            label = 'MALWARE_CLASS'
        elif info['type'] == 'instance':
            label = 'MALWARE_INDIVIDUAL'
        elif info['type'] == 'relation':
            label = 'MALWARE_RELATION'
        else:
            continue  # Skip unknown types

        # Split term into tokens and set LOWER attribute for case-insensitive matching
        term_tokens = term.split()
        pattern = [{'LOWER': token.lower()} for token in term_tokens]
        
        patterns.append({
            'label': label,
            'pattern': pattern,
            'id': term
        })

    return patterns

def process_article(title, preprocessed_content, nlp, ontology_terms):
    """Process a single article and extract entities with relationships."""
    # Combine title and preprocessed content with a separator
    combined_text = f"{title} . {preprocessed_content}"
    doc = nlp(combined_text)
    entities_info = {}
    
    # Process entities from sent.ents, including ontology entities
    for sent in doc.sents:
        for ent in sent.ents:
            # Define all relevant labels
            relevant_labels = ['ORG', 'PERSON', 'PRODUCT', 'GPE', 'TECHNOLOGY', 
                               'MALWARE_CLASS', 'MALWARE_INDIVIDUAL', 'MALWARE_RELATION']
            
            if ent.label_ in relevant_labels:
                relationships = extract_meaningful_relationships(ent, sent)
                
                if ent.text not in entities_info:
                    is_ontology = ent.label_ in ['MALWARE_CLASS', 'MALWARE_INDIVIDUAL', 'MALWARE_RELATION']
                    entities_info[ent.text] = {
                        'type': ent.label_,
                        'is_ontology': is_ontology,
                        'relationships': relationships,
                        'mentions': 1
                    }
                else:
                    entities_info[ent.text]['mentions'] += 1
                    entities_info[ent.text]['relationships'].extend(relationships)
    
    return entities_info

def test_entity_recognition(nlp):
    """Test the spaCy model to ensure ontology entities are recognized.

    Args:
        nlp (spacy.lang): The spaCy language model with EntityRuler added.
    """
    test_text = "The Zeus malware was detected in the network."
    doc = nlp(test_text)
    for sent in doc.sents:
        for ent in sent.ents:
            print(f"{ent.text}: {ent.label_}")

def main():
    # Define input and output paths
    input_path = 'C:\\Users\\HP\\Documents\\bakalarka\\BERT Classifier\\scripts\\filter_articles_by_label\\filtered_malware_articlesStrba.csv'
    output_path = 'C:\\Users\\HP\\Documents\\bakalarka\\spacy_with_ontology\\malware_entitiesStrba.csv'
    
    # Load ontology terms
    ontology_path = 'C:\\Users\\HP\\Documents\\bakalarka\\spacy_with_ontology\\MALont.owl'
    ontology_terms = load_ontology_terms(ontology_path)
    
    # Load spaCy model with ontology terms
    nlp = load_spacy_model(ontology_terms)
    
    # Test entity recognition
    print("Testing entity recognition:")
    test_entity_recognition(nlp)
    
    # Proceed with processing articles
    df = pd.read_csv(input_path)
    
    all_entities = []
    
    for _, row in df.iterrows():
        title = row['Title']
        link = row['Link'] if 'Link' in row else ''  # Get the link if available
        preprocessed_content = row['Preprocessed_Content']
        
        # Skip if preprocessed content is missing or NaN
        if pd.isna(preprocessed_content):
            continue
            
        entities_info = process_article(title, preprocessed_content, nlp, ontology_terms)
        
        # Format entities for output
        for entity, info in entities_info.items():
            if not info['relationships']:
                # For entities with no relationships, add at least one row
                entity_data = {
                    'Article_Title': title,
                    'Article_Link': link,
                    'Entity': entity,
                    'Entity_Type': info['type'],
                    'Related_Phrase': '',
                    'Related_To': '',
                    'Total_Mentions': info['mentions']
                }
                all_entities.append(entity_data)
            else:
                # For entities with relationships, add a row for each relationship
                for rel in info['relationships']:
                    entity_data = {
                        'Article_Title': title,
                        'Article_Link': link,
                        'Entity': entity,
                        'Entity_Type': info['type'],
                        'Related_Phrase': rel['related_phrase'],
                        'Related_To': rel['related_to'],
                        'Total_Mentions': info['mentions']
                    }
                    all_entities.append(entity_data)
    
    # Create and save the output DataFrame
    output_df = pd.DataFrame(all_entities)
    output_df.to_csv(output_path, index=False)

if __name__ == "__main__":
    main() 